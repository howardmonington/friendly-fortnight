{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1: Data Cleaning and Exploratory Data Analysis \n",
    "***\n",
    "\n",
    "**Name**: \n",
    "\n",
    "***\n",
    "\n",
    "This assignment is due on Moodle by **5pm on Friday September 14th**. Your solutions to theoretical questions should be done in Markdown directly below the associated question.  Your solutions to computational questions should include any specified Python code and results as well as written commentary on your conclusions.  Remember that you are encouraged to discuss the problems with your classmates, but **you must write all code and solutions on your own**.   \n",
    "\n",
    "**NOTES**: \n",
    "\n",
    "- Unless a url is given for a data set, you will find the required data in the same directory as this assignment on GitHub.\n",
    "- If you're not familiar with typesetting math directly into Markdown then by all means, do your work on paper first and then typeset it later.  Remember that there is a [reference guide](https://math.meta.stackexchange.com/questions/5020/mathjax-basic-tutorial-and-quick-reference) linked on Piazza on writing math in Markdown. \n",
    "- It is **bad form** to make your reader interpret numerical output from your code.  If a question asks you to compute some value from the data you should show your code output **AND** write a summary of the results in Markdown directly below your code. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1 \n",
    "***\n",
    "\n",
    "Rebecca cares about [octopuses](https://english.stackexchange.com/questions/270/what-is-the-correct-plural-of-octopus/271). She cares so much that, up and down the coast, she opens octopus rescues, octopus temporary housing, and octopus sanctuaries, specifically targeted at juveniles in need. For convenience, we will refer to all the Juvenile Octopus Rescues, Temps, and Sanctuaries as \"JORTS.\"\n",
    "\n",
    "Rebecca wants to estimate the average food consumption across the JORTS this month so that she can plan the food orders for next month. She has 14 Rescues, 35 Temporary houses, and 56 Sanctuaries. What an empire!\n",
    "\n",
    "Rebecca opens up the *JORTS Manager App* on her phone, which gives her a list of all of her coastal operations. She randomly picks 15 of them, and gets ready to email their managers asking for the monthly food reports. Of course, Rebecca has taken CSCI 3022, so she knows a thing or two about sampling, and so, to get a good estimate of the monthly food consumption (kilograms per month) for typical JORTS, she intentionally chooses 2 Rescues, 5 Temporary houses, and 8 Sanctuaries.\n",
    "\n",
    "Identify the following: \n",
    "\n",
    "- the population \n",
    "- the sample frame \n",
    "- the sample \n",
    "- the type of sample \n",
    "- the quantity of interest "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### P1 Answers:\n",
    "***\n",
    "__Population__ : All of Rebecca's _JORTS_<br>\n",
    "__Sample Frame__ : Emails from individual _JORTS_ managers<br>\n",
    "__Sample__ : 15 _JORTS_ that she randomly picked<br>\n",
    "__Type of Sample__ : Stratified Sample<br>\n",
    "__Quantity of Interest__ : Monthly food consumption (kilograms per month) for typical _JORTS_<br>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2 \n",
    "***\n",
    "\n",
    "A method to investigate the sensitivity of the sample mean and the sample median to extreme outliers and changes in the dataset is to replace one or more elements in a given dataset by a number $y$ and investigate the eﬀect when $y$ changes. To illustrate this, consider the dataset\n",
    "\n",
    "$$\n",
    "4.6 \\quad \n",
    "5.0 \\quad\n",
    "6.5 \\quad\n",
    "7.7 \\quad\n",
    "y \\quad\n",
    "4.2 \\quad\n",
    "1.9\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part A**: Compute the sample mean and sample median for $y=0$. Compute them both again for $y=10$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.3 µs ± 2.96 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "6.31 µs ± 126 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "92.2 µs ± 1.13 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "31.4 µs ± 562 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit A1 = pd.Series([4.6, 5.0, 6.5, 7.7, 0, 4.2, 1.9]).mean()\n",
    "%timeit A2 = np.array([4.6, 5.0, 6.5, 7.7, 0, 4.2, 1.9]).mean()\n",
    "%timeit P1 = pd.Series([4.6, 5.0, 6.5, 7.7, 0, 4.2, 1.9]).median()\n",
    "%timeit P2 = np.median(Y0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### Results of Timing Test: \n",
    "Comparing the mean and median functions of NumPy and Pandas shows that NumPy is faster for both operations so this is what I'll use to calculate the sample mean and median for y = 0 and y = 10\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample mean (y = 0): 4.271428571428571\n",
      "Sample median (y = 0): 4.6\n",
      "Sample mean (y = 10): 5.7\n",
      "Sample median (y = 10): 5.0\n",
      "9.8 -1.0000000000000009\n"
     ]
    }
   ],
   "source": [
    "defaultArray = np.array([4.6, 5.0, 6.5, 7.7, 4.2, 1.9])\n",
    "Y0 = np.append(defaultArray, 0)\n",
    "Y10 = np.append(defaultArray, 10)\n",
    "mean0 = Y0.mean()\n",
    "median0 = np.median(Y0)\n",
    "mean10 = Y10.mean()\n",
    "median10 = np.median(Y10)\n",
    "print(\"Sample mean (y = 0): \" + mean0.astype(str))\n",
    "print(\"Sample median (y = 0): \" + median0.astype(str))\n",
    "print(\"Sample mean (y = 10): \" + mean10.astype(str))\n",
    "print(\"Sample median (y = 10): \" + median10.astype(str))\n",
    "#to find out if these are outliers according to the definition within the boxplot section in the textbook, find 1.5*IQR\n",
    "q75, q25 = np.percentile(Y0, [75 ,25])\n",
    "iqr = q75 - q25\n",
    "topWhisker = q75 + 1.5 * iqr\n",
    "bottomWhisker = q25 - 1.5*iqr\n",
    "print(topWhisker, bottomWhisker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### Part A Conclusion:\n",
    "To compare how the values 0 and 10 affect the mean and median when adjusting Y, I made two arrays and calculated the median and mean for each. I also calculated the top whisker and bottom whisker amount to compare these values to the defintion of _outlier_ from the section of the book on _BoxPlots_. Both of these values are close the outskirts of what is considered an outlier, so nothing can really be said about the sensitivity to outliers by comparing these two values, because they are so close to the \"borders\" of outliers but on opposite ends of the spectrum.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B**: What should $y$ be if we want the mean to be equal to $10$? What should $y$ be if we want the mean to be equal to $0$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x bar = 10\n",
      "40.1\n",
      "x bar = 0\n",
      "-29.9\n"
     ]
    }
   ],
   "source": [
    "#find the xk for mean, with some error checking for accuracy\n",
    "# def findXkForMean(a, mean):\n",
    "#     returnVal = ((mean * (defaultArray.size + 1)) - (defaultArray.sum()))\n",
    "#     finalArray = np.append(a,returnVal)\n",
    "#     assert(equal_float(mean, finalArray.mean()))\n",
    "#     return ((mean * (defaultArray.size + 1)) - (defaultArray.sum()))\n",
    "\n",
    "#arbitrary 0.001 chosen for value to compare int to float for error checking\n",
    "# def equal_float(a,b):\n",
    "#     return abs(a-b) <= 0.001\n",
    "    \n",
    "def find_xk_for_mean(data_set, mean):\n",
    "    return ((mean * (data_set.size + 1)) - (data_set.sum()))\n",
    "\n",
    "print(\"x bar = 10\")\n",
    "print(find_xk_for_mean(defaultArray, 10))\n",
    "print(\"x bar = 0\")\n",
    "print(find_xk_for_mean(defaultArray, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "(Mostly for practice using LaTeX)<br>\n",
    "__Mean__: $$\\bar{x}=\\frac{1}{n}\\sum_{k=1}^{n}x_k$$\n",
    "__Mean (Expanded)__: $$\\bar{x} = \\frac{x_1 + x_2 + \\ldots + x_n}{n}$$ \n",
    "__Solve for__ ${x_k}$ __to get prefered mean:__ \n",
    "$$\\bar{x} = \\frac{x_1 + x_2 + \\ldots + x_k + \\ldots + x_n}{n}$$ \n",
    "Times n\n",
    "$$\\bar{x} * n = x_1 + x_2 + \\ldots + x_k + \\ldots + x_n$$ \n",
    "Subtract $x_k$\n",
    "$$(\\bar{x} * n) - x_k = x_1 + x_2 + \\ldots + x_{k-1} + x_{k+1} + \\ldots + x_n$$ \n",
    "Subtract $(\\bar{x} * n)$\n",
    "$$-x_k = x_1 + x_2 + \\ldots + x_{k-1} + x_{k+1} + \\ldots + x_n - (\\bar{x}*n)$$\n",
    "Times -1\n",
    "$$x_k = (\\bar{x}*n) - (x_1 + x_2 + \\ldots + x_{k-1} + x_{k+1} + \\ldots + x_n)$$\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### Part B Conclusion:\n",
    "We can really tweak the mean of a dataset by adding crazy outliers to the set, showcasing the volatility of the mean when dealing with a dataset that has some serious outliers.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part C**: Compute the sample median for the following cases: \n",
    "- $y=10$ \n",
    "- $y=100$ \n",
    "- $y \\to \\infty$ \n",
    "- $y=5.01$ \n",
    "- $y=4.99$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = 10; median = 5.0\n",
      "y = 100; median = 5.0\n",
      "y = inf; median = 5.0\n",
      "y = 5.01; median = 5.0\n",
      "y = 4.99; median = 4.99\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "def median_when_adding_datum(data_set, datum_to_add):\n",
    "    return np.median(np.append(data_set, datum_to_add))\n",
    "\n",
    "ten = median_when_adding_datum(defaultArray, 10)\n",
    "print(f'y = 10; median = {ten}')\n",
    "hundred = median_when_adding_datum(defaultArray, 100)\n",
    "print(f'y = 100; median = {hundred}')\n",
    "#use traditional maxsize of int to represent infinity in this case,\n",
    "#where we don't need infinity to get the same result as a REALLY big value\n",
    "inf = median_when_adding_datum(defaultArray, sys.maxsize)\n",
    "print(f'y = inf; median = {ten}')\n",
    "five_o_one = median_when_adding_datum(defaultArray, 5.01)\n",
    "print(f'y = 5.01; median = {five_o_one}')\n",
    "four_nine_nine = median_when_adding_datum(defaultArray, 4.99)\n",
    "print(f'y = 4.99; median = {four_nine_nine}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### Part C Conclusion:\n",
    "The information from the results of the cell above show that even with extreme outliers, such as an infinite value, do not make drastic changes to the median. This is illustrated by all of the median values being the same except for a small change for the last value of Y.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Part D**: Think about the previous parts, above, and describe in words or mathematical notation the answers to the following two questions:\n",
    "\n",
    "- By varying $y$, what is the set of all the possible values that the sample mean could take on?\n",
    "- By varying $y$, what is the set of all the possible values that the sample median could take on?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### Part D Conclusions:\n",
    "By varying y, the set of all the possible values that the sample __mean__ could take on is $\\mathbb{R}$.\n",
    "\n",
    "This can be proven by showing that our definition of mean approaches $\\infty$ as y ($x_k$) changes (if there is no $y\\to-\\infty$ elsewhere in the set) <br><br>\n",
    "$$\\lim_{x_k\\to\\infty}\\frac{x_1 + x_2 + \\ldots + x_k + \\ldots + x_n}{n} = \\infty$$\n",
    "And by showing that our definition of mean approaches $-\\infty$ as y ($x_k$) changes (if there is no $y\\to\\infty$ elsewhere in the set) <br><br>\n",
    "$$\\lim_{x_k\\to-\\infty}\\frac{x_1 + x_2 + \\ldots + x_k + \\ldots + x_n}{n} = -\\infty$$\n",
    "\n",
    "__Conclusion Mean__:<br>\n",
    "These limits are true because the numerator tends towards + or - $\\infty$ while the denominator remains constant. If we vary Y based on the set of all $\\mathbb{R}$, it follows that the mean could be anywhere in $\\mathbb{R}$ because of the infinite precision of Real Numbers.\n",
    "***\n",
    "When considering the __median__, there are a few cases that we can consider to prove what the possible values are.\n",
    "First, to make things easier, we sort the dataset and take out y.\n",
    "$$\n",
    "1.9 \\quad\n",
    "4.2 \\quad\n",
    "4.6 \\quad\n",
    "5.0 \\quad\n",
    "6.5 \\quad\n",
    "7.7\n",
    "$$\n",
    "There are 6 elements of this dataset, but when we add a (varying) y, there will be 7. The mean of the final dataset we will consider is the 4th element which separates the data into equal halves.\n",
    "\n",
    "__Case 1:__ <br>\n",
    "Possible Sets:\n",
    "$$\n",
    "1.9 \\quad\n",
    "4.2 \\quad\n",
    "4.6 \\quad\n",
    "y \\quad\n",
    "5.0 \\quad\n",
    "6.5 \\quad\n",
    "7.7\n",
    "$$\n",
    "If we add Y to the 4th spot in the dataset, the median value is guarenteed to be y itself. If in element 4, that makes the set of possible y values $\\{y\\in\\mathbb{R}\\: | \\: 4.6\\le y \\le 5.0\\}$ set of this type will be denoted as $[4.6, 5.0]$ from here on out. So.... for Case 1, $Med(dataset) = [4.6, 5.0]$<br><br>\n",
    "__Case 2:__ <br>\n",
    "Possible Sets:\n",
    "$$\n",
    "y \\quad\n",
    "1.9 \\quad\n",
    "4.2 \\quad\n",
    "4.6 \\quad\n",
    "5.0 \\quad\n",
    "6.5 \\quad\n",
    "7.7\n",
    "$$\n",
    "$$\n",
    "1.9 \\quad\n",
    "y \\quad\n",
    "4.2 \\quad\n",
    "4.6 \\quad\n",
    "5.0 \\quad\n",
    "6.5 \\quad\n",
    "7.7\n",
    "$$\n",
    "$$\n",
    "1.9 \\quad\n",
    "4.2 \\quad\n",
    "y \\quad\n",
    "4.6 \\quad\n",
    "5.0 \\quad\n",
    "6.5 \\quad\n",
    "7.7\n",
    "$$\n",
    "If we add Y to the 1st-3rd spot in the dataset, this makes possible values for y $(-\\infty, 4.6]$. These values of y will guarentee a median of 4.6. So... for Case 2, $Med(dataset) = 4.6$<br><br>\n",
    "__Case 3:__ <br>\n",
    "Possible Sets:\n",
    "$$\n",
    "1.9 \\quad\n",
    "4.2 \\quad\n",
    "4.6 \\quad\n",
    "5.0 \\quad\n",
    "y \\quad\n",
    "6.5 \\quad\n",
    "7.7\n",
    "$$\n",
    "$$\n",
    "1.9 \\quad\n",
    "4.2 \\quad\n",
    "4.6 \\quad\n",
    "5.0 \\quad\n",
    "6.5 \\quad\n",
    "y \\quad\n",
    "7.7\n",
    "$$\n",
    "$$\n",
    "1.9 \\quad\n",
    "4.2 \\quad\n",
    "4.6 \\quad\n",
    "5.0 \\quad\n",
    "6.5 \\quad\n",
    "7.7 \\quad\n",
    "y\n",
    "$$\n",
    "If we add Y to the 5th-7th spot in the dataset, this makes possible values for y $[5.0, \\infty)$. These values of y will guarentee a median of 5.0. So... for Case 3, $Med(dataset) = 5.0$\n",
    "\n",
    "__Conclusion Median__:<br>\n",
    "The first case includes both of the second cases, so the final possible values for $\\{y \\in \\mathbb{R}\\}$ is $Med(dataset) = [4.6, 5.0]$\n",
    "\n",
    "### Part D Conclusion:\n",
    "Clearly based on these results we can determine that the mean varies wildly for possible outliers in the dataset while the median is much more contained for varying values of y.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3 \n",
    "***\n",
    "\n",
    "Let $x_1, x_2, \\ldots, x_n$ be $n$ observations of a variable of interest.  Recall that the sample mean $\\bar{x}_n$ and sample variance $s^2_n$ are given by \n",
    "\n",
    "$$\n",
    "\\bar{x}_n = \\frac{1}{n}\\sum_{k=1}^n x_k \\quad \\textrm{and} \\quad s^2_n = \\frac{1}{n-1}\\sum_{k=1}^n \\left( x_k - \\bar{x}_n\\right)^2\n",
    "$$\n",
    "\n",
    "where here the subscript $n$'s indicate the number of observations in the sample. Notice that a natural computation of the variance requires two passes over the data: one to compute the mean, and a second to subtract the mean from each observation and compute the sum of squares. It is often useful to be able to compute the variance in a single pass, inspecting each value $x_k$ only once; for example, when the data are being collected without enough storage to keep all the values, or when costs of memory access dominate those of computation. In this problem you will explore two methods for such an _online_ computation of the mean and variance.  \n",
    "\n",
    "**Part A**: Show algebraically that the following relation holds between the mean of the first $n-1$ observations and the mean of all $n$ observations: \n",
    "\n",
    "$$\n",
    "\\bar{x}_n = \\bar{x}_{n-1} + \\frac{x_n - \\bar{x}_{n-1}}{n}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\n",
    "$$\n",
    "\\bar{x}_n = \\bar{x}_{n-1} + \\frac{x_n - \\bar{x}_{n-1}}{n}\n",
    "$$\n",
    "2.\n",
    "$$\n",
    "(\\bar{x}_n * n) = (\\bar{x}_{n-1} * n) + x_n - \\bar{x}_{n-1}\n",
    "$$\n",
    "3.\n",
    "$$\n",
    "((\\frac{1}{n}\\sum_{k=1}^n x_k) * n) = (\\bar{x}_{n-1} * n) + x_n - \\bar{x}_{n-1}\n",
    "$$\n",
    "4.\n",
    "$$\n",
    "(\\sum_{k=1}^n x_k) = (\\bar{x}_{n-1} * n) + x_n - \\bar{x}_{n-1}\n",
    "$$\n",
    "5.\n",
    "$$\n",
    "(\\sum_{k=1}^n x_k) = (\\bar{x}_{n-1} * n) + x_n + (\\bar{x}_{n-1} * (-1))\n",
    "$$\n",
    "6.\n",
    "$$\n",
    "(\\sum_{k=1}^n x_k) = ((\\frac{1}{n - 1})\\sum_{k=1}^{n - 1} x_k) * (n - 1) + x_n\n",
    "$$\n",
    "7.\n",
    "$$\n",
    "(\\sum_{k=1}^n x_k) = (\\sum_{k=1}^{n - 1} x_k) + x_n\n",
    "$$\n",
    "8.\n",
    "$$\n",
    "(\\sum_{k=1}^n x_k) = x_1 + x_2 + \\dots + x_{n-1} + x_n\n",
    "$$\n",
    "9.\n",
    "$$\n",
    "\\sum_{k=1}^n x_k = \\sum_{k=1}^n x_k \\blacksquare\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B**: Write a function `my_sample_mean` that takes as its input a numpy array and returns the mean of that numpy array using the formulas from class (written above). You may *not* use numpy's built in mean function. Write another function `my_sample_var` that takes as its input a numpy array and returns the variance of that numpy array, again using the formulas from class (written above). You may *not* use any built-in sample variance functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_sample_mean(numpyarr):\n",
    "    return numpyarr.sum()/numpyarr.size\n",
    "\n",
    "def my_sample_var(numpyarr):\n",
    "    mean = my_sample_mean(numpyarr)\n",
    "    n = numpyarr.size\n",
    "    inside_sum = np.vectorize(lambda x: (x - mean)**2)(numpyarr) \n",
    "    return (1/(n - 1))*inside_sum.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### Part B Conclusion:\n",
    "We take these built-in functions for granted! That was a headache. (and a lot of Google-fu... Vectorizing functions?? For such a small data set?? Might as well get some practice :D)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part C**: Use your functions from Part B to compute the sample mean and sample variance of the following array, which contains the counts of perfectly round suckers found on a set of aquarium octopuses.\n",
    "\n",
    "`octopus_suckers = [25, 29, 40, 19, 7, 6, 3, 11, 19, 21, 22, 45, 27]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 21.076923076923077\n",
      "Variance: 158.9102564102564\n"
     ]
    }
   ],
   "source": [
    "#dataset definition\n",
    "octopus_suckers = np.array([25, 29, 40, 19, 7, 6, 3, 11, 19, 21, 22, 45, 27])\n",
    "\n",
    "#arbitrary 0.001 chosen for value to compare floats to compensate for small errors\n",
    "def equal_float(a,b):\n",
    "    return abs(a-b) <= 0.001\n",
    "\n",
    "def test_my_sample_var(numpyarr):\n",
    "    assert(equal_float(my_sample_var(numpyarr), np.var(numpyarr, ddof=1)))\n",
    "    \n",
    "def test_my_sample_mean(numpyarr):\n",
    "    assert(my_sample_mean(numpyarr) == numpyarr.mean())\n",
    "\n",
    "    \n",
    "#test functions\n",
    "test_my_sample_var(octopus_suckers)\n",
    "test_my_sample_mean(octopus_suckers)\n",
    "\n",
    "#define\n",
    "mean = my_sample_mean(octopus_suckers)\n",
    "var = my_sample_var(octopus_suckers)\n",
    "\n",
    "#print\n",
    "print(f'Mean: {mean}')\n",
    "print(f'Variance: {var}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### Part C Conclusion:\n",
    "The functions work as tested against the values computed by NumPy.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part D**: Implement a third function called `update_mean` that implements the formula whose valdity you proved in Part A. (Note: this function will need to take as its input three things: $x_n$, $\\bar{x}_{n-1}$ and $n$.)\n",
    "\n",
    "Use this function to compute the values that you get from taking the mean of the first suckers count, the first two suckers counts, the first three suckers counts, and so on up to all the suckers counts. Store your means in a numpy array called `sucker_means`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean from updating: 21.076923076923077\n",
      "Testing...\n"
     ]
    }
   ],
   "source": [
    "#tail recursion doesn't matter in python but let's try it anyway...\n",
    "#returns a float, what kind of float i'm not really sure yet...\n",
    "def update_mean(x_n, mean_x_n_minus_one, n):\n",
    "    return mean_x_n_minus_one + ((x_n - mean_x_n_minus_one)/n)\n",
    "\n",
    "sucker_means = 0\n",
    "for i in range(0, octopus_suckers.size):\n",
    "    sucker_means = update_mean(octopus_suckers[i], sucker_means, i + 1)\n",
    "    \n",
    "print(f'Mean from updating: {sucker_means}')\n",
    "#test\n",
    "print(\"Testing...\")\n",
    "assert(equal_float(sucker_means, octopus_suckers.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.076923076923077\n"
     ]
    }
   ],
   "source": [
    "#recursive would be a more elegant solution\n",
    "def update_mean_rec(numpyarr):    \n",
    "    #uninformed precondition\n",
    "    assert(numpyarr.size >= 1)\n",
    "    \n",
    "    #base cases\n",
    "    if numpyarr.size == 1:\n",
    "        return numpyarr.sum()\n",
    "    elif numpyarr.size == 2:\n",
    "        return numpyarr[0] + (1/2)*(numpyarr[1] - numpyarr[0])\n",
    "    \n",
    "    #inductive step\n",
    "    cutoff_index = numpyarr.size - 1\n",
    "    new_arr = numpyarr[:cutoff_index]\n",
    "    return update_mean_rec(new_arr) + (numpyarr[cutoff_index] - update_mean_rec(new_arr))/numpyarr.size\n",
    "\n",
    "print(update_mean_rec(octopus_suckers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "(Extras for the recursive version...)\n",
    "***\n",
    "__Base Case Algebraically for reference__<br>\n",
    "1.\n",
    "$$\n",
    "\\bar{x}_n = \\bar{x}_{n-1} + \\frac{x_n - \\bar{x}_{n-1}}{n}, n = 2\n",
    "$$\n",
    "2.\n",
    "$$\n",
    "\\bar{x}_2 = \\bar{x}_{1} + \\frac{x_2 - \\bar{x}_{1}}{2}\n",
    "$$\n",
    "3.\n",
    "$$\n",
    "\\bar{x}_2 = x_1 + \\frac{x_2 - x_1}{2}\n",
    "$$\n",
    "4.\n",
    "$$\n",
    "\\bar{x}_2 = x_1 + \\frac{1}{2}(x_2 - x_1)\n",
    "$$\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### Part D Conclusion:\n",
    "There is a way to solve the mean using this inductive method both recursively and not so recursively. This allows the mean to be calculated one step at a time instead of having to sum all of the pieces together and then find it that way.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4\n",
    "*** \n",
    "Some claim that the final hours aboard the RMS Titanic were marked by \"class warfare\" in which the people with first-class tickets took all the good spots on the lifeboats; others claim that the final hours were characterized by male chivalry, in which the men valiantly gave up their positions in the boats and succumbed bravely to the depths of the Atlantic. \n",
    "\n",
    "We have the data on survival rates by class and by sex, so let's figure out whether there is evidence for these scenarios. Access the titanic data in `titanic_data.csv` and store it in a Pandas DataFrame. The data contains information pertaining to class status (**Pclass**), survival of passengers (**Survived**), and gender (**Sex**), among others.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  36.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  18.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  14.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  27.0      1   \n",
       "4                           Allen, Mr. William Henry    male  63.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"titanic_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part A**: Consider the two claims: class warfare, and male chivalry. Suppose that class warfare occurred in the final hours aboard the Titanic.  What patterns might you expect to see in the data?  Suppose that male chivalry was widespread during the final hours insteas. What patterns might you then expect to see in the data?  Explain both of these hypothesized patterns in words. Are these two hypotheses mutually exclusive or not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B**: Create a clean data set by removing any rows from the DataFrame that are missing values corresponding to **Survived**, **Pclass**, **Age**, or **Sex**. Store the clean data in a DataFrame called dfTitanic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part C**: Determine the fraction of survivors from each passenger class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part D**: Compute the fraction of survivors according to class and gender.  Did men in first class or women in third class have a higher survival rate? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part E**: How would you characterize the distribution of **AGE**? (By _characterize_ we mean that you should indicate whether the data are unimodal, bimodal, multimodal, symmetric, negatively skewed, positively skewed, etc.)  Make any necessary graphical summaries to justify your conclusion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part F**: Were the median and mean ages for females who survived higher or lower than for females who did not survive?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part G**: Do the data suggest class warfare, male chivalry, or some combination of both characteristics in the final hours aboard the Titanic?  Justify your conclusion based on the computations done above, or do any other analysis that you like, but be sure to clearly justify your conclusion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5 - No arm in another tentacle problem, eh?\n",
    "***\n",
    "\n",
    "_Octopuses have eight arms, which are often called tentacles._ \n",
    "\n",
    "While technically a fact about the noble octopus, this doesn't really do much for the imagination. Go find another octopus fact that you think is cool *and* that you think no one else is likely to report! In fact, *if your fact is unique, you'll earn extra credit on this problem*! Submit your fact [here](https://docs.google.com/forms/d/e/1FAIpQLScjminsyl9Q1d_OswAXHNLKPj9Gu-00qhVsy07VYDZC8d36LQ/viewform?usp=sf_link)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 6 - Dirty Data\n",
    "***\n",
    "Access the data from url https://www.stat.berkeley.edu/~statlabs/data/babies.data and store the information in a Pandas DataFrame.  A description of the variables can be found at https://www.stat.berkeley.edu/~statlabs/labs.html.  These data are a subset from a much larger study dealing with child health and development. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bwt</th>\n",
       "      <th>gestation</th>\n",
       "      <th>parity</th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>smoke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>120</td>\n",
       "      <td>284</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>62</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>113</td>\n",
       "      <td>282</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>64</td>\n",
       "      <td>135</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>128</td>\n",
       "      <td>279</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>64</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>123</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>69</td>\n",
       "      <td>190</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>108</td>\n",
       "      <td>282</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>67</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>136</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>62</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>138</td>\n",
       "      <td>244</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>62</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>132</td>\n",
       "      <td>245</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>65</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>120</td>\n",
       "      <td>289</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>62</td>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>143</td>\n",
       "      <td>299</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>66</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bwt  gestation  parity  age  height  weight  smoke\n",
       "0  120        284       0   27      62     100      0\n",
       "1  113        282       0   33      64     135      0\n",
       "2  128        279       0   28      64     115      1\n",
       "3  123        999       0   36      69     190      0\n",
       "4  108        282       0   23      67     125      1\n",
       "5  136        286       0   25      62      93      0\n",
       "6  138        244       0   33      62     178      0\n",
       "7  132        245       0   23      65     140      0\n",
       "8  120        289       0   25      62     125      0\n",
       "9  143        299       0   30      66     136      1"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"https://www.stat.berkeley.edu/~statlabs/data/babies.data\", delim_whitespace=True)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Part A**: Create a clean data set that removes subjects if any observations on the subject are unknown.  Note that that collectors of the data set used values like $9$, $99$, $999$, to denote unknown values.  You can look at the documentation linked in the problem description to determine which unknown-value marker was used for each characteristics.  Store the modified data set in a Pandas DataFrame called dfBabies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B**: Use the information in dfBabies to create a density histogram of the birth weights of babies whose mothers have never smoked (smoke=0) and another histogram placed directly below the first in the same graphics device for the birth weights of babies whose mothers currently smoke (smoke=1).  Make the range of the horizontal axis $30$ to $180$ (ounces) for both histograms.  Make sure to give each subplot titles and label axes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part C**: Based on the histograms in **Part B**, characterize the distribution of baby birth weights for both non-smoking and smoking mothers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part D**: What are the mean and median weight difference between babies of smokers and non-smokers?  Can you think of any reason not to use the mean as a measure of center to compare birth weights for this problem? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part E**: Create side-by-side box-and-whisker plots to compare the birth weights of babies whose mothers never smoked and those who currently smoke.  Use the box-and-whisker plot conventions discussed in lecture. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part F**: Using the box-and-whisker plots from **Part E** comment on the distributions of body weights of babies within each smoking / non-smoking groups as well as the comparison of the two classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge Problem\n",
    "***\n",
    "\n",
    "In every homework assignment we'll give you a Challenge Problem.  Challenge Problems never need to be turned in (and in fact, will not be graded) but we encourage you to give them a shot (after completing the required homework problems) and discuss them with your classmates and your instructors.  \n",
    "\n",
    "In the 1954 book _How to Lie with Statistics_ authors Darrell Huff and Irving Geis describe many common ways that people concoct misleading graphics.  An excerpt from these chapters can be found [here](https://piazza.com/class_profile/get_resource/j6pfvv6b9ze4gi/j771gy7fdpe3e7).  \n",
    "\n",
    "Your job is to go out onto the web and find some data that you find interesting.  Then create both a misleading and a non-misleading version of a graphical summary for the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
