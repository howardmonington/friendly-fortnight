{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='top'></a>\n",
    "\n",
    "# Homework 6: Bootstrapping, Hypothesis Testing, P-Hacking, and Simple Linear Regression \n",
    "***\n",
    "\n",
    "**Name**: \n",
    "\n",
    "***\n",
    "\n",
    "This assignment is due on Moodle by **5 PM on Friday November 30**. Your solutions to theoretical questions should be done in Markdown/MathJax directly below the associated question.  Your solutions to computational questions should include any specified Python code and results as well as written commentary on your conclusions.  Remember that you are encouraged to discuss the problems with your instructors and classmates, but **you must write all code and solutions on your own**. \n",
    "\n",
    "**NOTES**: \n",
    "\n",
    "- Do **NOT** load or use any Python packages that are not available in Anaconda 3.6. \n",
    "- Some problems with code may be autograded.  If we provide a function API **do not** change it.  If we do not provide a function API then you're free to structure your code however you like. \n",
    "- Because you can technically evaluate notebook cells is a non-linear order, it's a good idea to do Cell $\\rightarrow$ Run All as a check before submitting your solutions.  That way if we need to run your code you will know that it will work as expected. \n",
    "- Submit only this Jupyter notebook to Moodle.  Do not compress it using tar, rar, zip, etc. \n",
    "- This should go without saying, but... For any question that asks you to calculate something, you **must show all work to receive credit**. Sparse or nonexistent work will receive sparse or nonexistent credit.\n",
    "\n",
    "---\n",
    "**Shortcuts:**  [Problem 1](#p1) | [Problem 2](#p2) | [Problem 3](#p3) | [Problem 4](#p4) | [Problem 5](#p5)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy import stats \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "[Back to top](#top)\n",
    "<a id='p1'></a>\n",
    "\n",
    "### [20 points] Problem 1 - Hypothesis Testing: Find-the-Knowledge-Bug \n",
    "\n",
    "As part of your job as a seasoned data science consultant, companies often bring you in to supervise their less-experienced data science teams before new product roll-outs.  One one such occasion, you are hired by a medium-sized internet-sales company that is preparing to release a new line of smart-home products.  Prior to their product release the company wants to do a targeted ad campaign to drive traffic to their site on launch day. \n",
    "\n",
    "You are asked to pair-up and do some inference work with a new employee named Ketelbells McKnowsNoStats. At various points in your day you catch Ketelbells making the following mistakes.  In each case, clearly explain to Ketelbells why his testing setup or conclusion is incorrect. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part A**: Ketelbells has pulled up some data on the characteristics of customers that visited the company's website over the previous month.  He wants to perform an analysis on the mean age of customers that visit the site.  Let $X$ be the random variable describing the age of a site visitor and suppose that the population mean for $X$ is $\\mu$. In particular, Ketelbells wants to see if the data suggests that the mean age of their customers is under 30 years old.   He decides to perform the test with a null hypothesis of $H_0: \\mu < 30$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "__Part A Conclusions:__\n",
    "The null hypothesis should always have an equals sign in it, and the alternative should be what is above.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B**: After the wonderful explanation you gave him after the previous debacle, Ketelbells has seen the error in his ways and decides instead to do his hypothesis test with a null hypothesis of $H_0: \\bar{x} = 30$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "__Part B Conclusions:__\n",
    "x bar is used to denote the sample mean which we can just calculate straight up without any testing. $\\mu$ would give the population mean which we use a test for\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part C**: Finally on track with reasonable hypotheses of $H_0: \\mu = 30$ and $H_1: \\mu < 30$, Ketelbells computes a p-value of $0.03$, and thus concludes that there is only a 3% probability that the null hypothesis is true. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "__Part C Conclusions:__\n",
    "The p-value is NOT the probability that the null hypothesis is true.  The p-value is the probability of getting a sample similar to the sample that we have given that the null hypothesis is true.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part D**: This time, with the hypotheses again $H_0: \\mu = 30$ and $H_1: \\mu < 30$, Ketelbells computes a normalized test-statistic of $z = -0.04$ for the mean age and concludes that since $z = -0.04 < 0.05$ there is sufficient statistical evidence at the $\\alpha = 0.05$ significance level that the mean age of their customers is less than 30.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "__Part D Conclusions:__\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "[Back to top](#top)\n",
    "<a id='p2'></a>\n",
    "\n",
    "### [20 points] Problem 2 - Evaluating Vehicle Performance \n",
    "\n",
    "A [1983 study](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.34.6358&rep=rep1&type=pdf) evaluated the gas mileage of a variety of cars manufactured between 1970 and 1983. The study also compiled other interesting attributes for each vehicle, but we will focus on the number of cylinders in the engine for this problem. More information on the data is available [here](https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/). Gas mileage is measured in miles-per-gallon, or mpg.\n",
    "\n",
    "**Part A:** Read the data set and store as a Pandas data frame. You will need figure out what additional arguments to `pd.read_csv()` must be provided in order to read the data set properly.\n",
    "\n",
    "Then, be sure to give all of the columns informative names, if they do not already have some.\n",
    "\n",
    "Finally, use `drop_na()` to drop any rows with missing values. Missing values are reported with a \"?\"."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398\n"
     ]
    }
   ],
   "source": [
    "colnames=['mpg','cylinders','displacement','horsepower','weight','acceleration','model year','origin','name']\n",
    "dfMPG = pd.read_csv('data/auto-mpg.data',sep='\\s+',names = colnames)\n",
    "dfMPG.replace('?', np.NaN)\n",
    "dfMPG = dfMPG.dropna()\n",
=======
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model year</th>\n",
       "      <th>origin</th>\n",
       "      <th>car name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>chevrolet chevelle malibu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>buick skylark 320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>plymouth satellite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>amc rebel sst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>ford torino</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement horsepower  weight  acceleration  model year  \\\n",
       "0  18.0          8         307.0      130.0  3504.0          12.0          70   \n",
       "1  15.0          8         350.0      165.0  3693.0          11.5          70   \n",
       "2  18.0          8         318.0      150.0  3436.0          11.0          70   \n",
       "3  16.0          8         304.0      150.0  3433.0          12.0          70   \n",
       "4  17.0          8         302.0      140.0  3449.0          10.5          70   \n",
       "\n",
       "   origin                   car name  \n",
       "0       1  chevrolet chevelle malibu  \n",
       "1       1          buick skylark 320  \n",
       "2       1         plymouth satellite  \n",
       "3       1              amc rebel sst  \n",
       "4       1                ford torino  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# give column names based on the data\n",
    "colnames = [\"mpg\",\n",
    "           \"cylinders\",\n",
    "           \"displacement\",\n",
    "           \"horsepower\",\n",
    "           \"weight\",\n",
    "           \"acceleration\",\n",
    "           \"model year\",\n",
    "           \"origin\",\n",
    "           \"car name\"]\n",
    "\n",
    "# read the csv and put the names\n",
    "dfMPG = pd.read_csv('data/auto-mpg.data', \n",
    "                    sep=\"\\s+\",\n",
    "                   names = colnames)\n",
    "\n",
    "# replace the ? char with NaN and drop those rows that have missing values\n",
    "# use regex because we don't know if there's some spaces mixed in there that we can't see\n",
    "dfMPG = dfMPG.replace(r\"\\s*\\?\\s*\", np.NaN, regex=True).dropna()\n",
    "\n",
>>>>>>> 8f0c89f636d911eb998005362d7a09099670d0a5
    "dfMPG.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B**: Assuming the data in this sample are representative of cars from the 1970-1983 time period, find a 95% confidence interval for the mean gas mileage (mpg) of all vehicles from this period. Can we conclude that the mean gas mileage is higher than 20 mpg? Be sure to show all calculations in Python. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "__Part B Work:__\n",
    "\n",
    "95% Confidence interval of the mean:\n",
    "\n",
    "$$\n",
    "    CI = \\bar{x} \\pm Z_{\\frac{\\alpha}{2}}\\frac{s}{\\sqrt{n}} \\\\\n",
    "    \\bar{x} = \\frac{1}{n}\\sum_{i = 1}^{n}{x_i} = 23.446 \\\\\n",
    "    s = \\sqrt{\\frac{1}{n-1}\\sum_{x = 1}^{n}{(x_i - \\bar{x})^2}} \\approx 7.805 \\\\\n",
    "    n = 392 \\\\\n",
    "    Z_{0.0005} \\approx 1.960 \\\\\n",
    "    CI_{lower} = \\bar{x} - Z_{\\frac{\\alpha}{2}}\\frac{s}{\\sqrt{n}} \\approx 22.673\\\\\n",
    "    CI_{upper} = \\bar{x} + Z_{\\frac{\\alpha}{2}}\\frac{s}{\\sqrt{n}} \\approx 24.219\\\\\n",
    "    CI = [22.673, 24.219]\n",
    "$$\n",
    "***\n",
    "__Part B Conclusions:__\n",
    "\n",
    "We are 95% confident that the mean does NOT include 20, and is stricly greater than 20.  With this information we can see significant evidence to conclude that the MPG of these cars is higher than 20 mpg.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min year: 70\n",
      "Max year: 82\n",
      "mean: 23.44591836734694 s: 7.805007486571799 n: 392\n",
      "z alpha / 2: 1.959963984540054\n",
      "lower: 22.673276244152817 upper: 24.218560490541066\n"
     ]
    }
   ],
   "source": [
    "# confirm that the cars are from 1970-1982\n",
    "print(f\"Min year: {min(dfMPG['model year'])}\\nMax year: {max(dfMPG['model year'])}\")\n",
    "\n",
    "# mean, n, and s\n",
    "mean = dfMPG['mpg'].mean()\n",
    "n = len(dfMPG)\n",
    "s = dfMPG['mpg'].std()\n",
    "\n",
    "# alpha / 2 = 0.025\n",
    "z = stats.norm.ppf(0.975)\n",
    "\n",
    "# compute the confidence interval\n",
    "lower = mean - z*(s/np.sqrt(n))\n",
    "upper = mean + z*(s/np.sqrt(n))\n",
    "\n",
    "print(f\"mean: {mean} s: {s} n: {n}\")\n",
    "print(f\"lower: {lower} upper: {upper}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part C**: You are considering buying a new car, but since [gas prices have recently increased dramatically](https://www.energy.gov/eere/vehicles/fact-915-march-7-2016-average-historical-annual-gasoline-pump-price-1929-2015), you are concerned about getting good fuel economy.\n",
    "\n",
    "Can you conclude at the $\\alpha=0.01$ significance level that the mean gas mileage for vehicles with 4 or 6 cylinder engines is more than 10 mpg better than the mean gas mileage for vehicles with 8 cylinder engines? You may consider two populations here: those vehicles with 4 or 6 cylinders, and those vehicles with 8 cylinders in their engines. Be sure to clearly describe your hypotheses and methodology, and show all relevant computations in Python. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "__Part C Work:__\n",
    "***\n",
    "\n",
    "$$\n",
    "    H_0: u_{8} - u_{46} = 10\n",
    "$$\n",
    "\n",
    "$$\n",
    "    H_1: u_{46} - u_{8} > 10\n",
    "$$\n",
    "\n",
    "***\n",
    "$$\n",
    "    CI_{mean difference} = (\\bar{x_{8}} - \\bar{x_{4-6}}) \\pm Z_{\\frac{\\alpha}{2}}\\sqrt{\\frac{s_{8}^2}{n_{8}} + \\frac{s_{4-6}^2}{n_{4-6}}} \\\\\n",
    "    z_{0.005} = 2.576 \\\\\n",
    "$$\n",
    "***\n",
    "__8 Cylinder Constants:__\n",
    "\n",
    "$$\n",
    "    s_{8} = \\sqrt{\\frac{1}{n-1}\\sum_{x = 1}^{n}{(x_i - \\bar{x})^2}} \\approx 2.836 \\\\\n",
    "    n_{8} = 103 \\\\\n",
    "    \\bar{x}_{8} = \\frac{1}{n}\\sum_{i = 1}^{n}{x_i} = 14.963 \\\\\n",
    "$$\n",
    "***\n",
    "__4-6 Cylinder Constants:__\n",
    "$$\n",
    "    s_{46} = \\sqrt{\\frac{1}{n-1}\\sum_{x = 1}^{n}{(x_i - \\bar{x})^2}} \\approx 6.708 \\\\\n",
    "    n_{46} = 282 \\\\\n",
    "    \\bar{x}_{46} = \\frac{1}{n}\\sum_{i = 1}^{n}{x_i} = 26.544 \\\\\n",
    "$$\n",
    "***\n",
    "__Final CI Calculations__:\n",
    "$$\n",
    "    CI_{\\text{upper}} = (\\bar{x_{8}} - \\bar{x_{46}}) + Z_{\\frac{\\alpha}{2}}\\sqrt{\\frac{s_{8}^2}{n_{8}} + \\frac{s_{46}^2}{n_{46}}} \\approx  -10.325\\\\\n",
    "    CI_{\\text{lower}} = (\\bar{x_{8}} - \\bar{x_{46}}) - Z_{\\frac{\\alpha}{2}}\\sqrt{\\frac{s_{8}^2}{n_{8}} + \\frac{s_{46}^2}{n_{46}}} \\approx  -12.836\\\\\n",
    "    CI: [-12.836, -10.325]\n",
    "$$\n",
    "***\n",
    "__Conclusions:__\n",
    "\n",
    "Because the confidence interval is strictly lower than -10, we can conclude that there is significant evidence at the 95% confidence level that the mean of 8 cylinder cars is lower than that of 4-6 cylinder cars by 10mpg.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z: 2.5758293035489004\n",
      "\n",
      "8 CYL\n",
      "mean: 14.963106796116508 n: 103 s: 2.8362841712789435\n",
      "\n",
      "4-6 CYL\n",
      "mean: 26.543617021276596 n: 282 s: 6.708462152436287\n",
      "\n",
      "CI lower: -12.836312926324004 upper: -10.324707523996173\n"
     ]
    }
   ],
   "source": [
    "z = stats.norm.ppf(0.995)\n",
    "print(f\"z: {z}\\n\")\n",
    "\n",
    "# 8 cyl\n",
    "cyl8 = dfMPG.loc[dfMPG['cylinders'] == 8]\n",
    "mean8 = cyl8['mpg'].mean()\n",
    "n8 = len(cyl8)\n",
    "s8 = cyl8['mpg'].std()\n",
    "\n",
    "# 4-6 cyl\n",
    "cyl46 = dfMPG.loc[(dfMPG['cylinders'] == 4) | (dfMPG['cylinders'] == 6)]\n",
    "mean46 = cyl46['mpg'].mean()\n",
    "n46 = len(cyl46)\n",
    "s46 = cyl46['mpg'].std()\n",
    "\n",
    "# CI calculations\n",
    "lower = (mean8 - mean46) - z*np.sqrt(s8**2/n8 + s46**2/n46)\n",
    "upper = (mean8 - mean46) + z*np.sqrt(s8**2/n8 + s46**2/n46) \n",
    "\n",
    "print(f\"8 CYL\\nmean: {mean8} n: {n8} s: {s8}\\n\")\n",
    "print(f\"4-6 CYL\\nmean: {mean46} n: {n46} s: {s46}\\n\")\n",
    "print(f\"CI lower: {lower} upper: {upper}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part D**: You decide to go with either a 4 or 6 cylinder engine, because if you buy an 8-cylinder vehicle that can haul heavy things, you just know you are going to get stuck helping people move. You just _know_ it.\n",
    "\n",
    "Conduct an appropriate hypothesis test at the $\\alpha=0.01$ significance level to determine if the mean gas mileage of vehicles with a 4-cylinder engine is significantly better than the gas mileage of vehicles with 6 cylinders. Be sure to clearly describe your hypotheses and methodology, and show all relevant computations in Python. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "__Part D Work:__\n",
    "***\n",
    "\n",
    "$$\n",
    "    H_0: u_{4} - u_{6} = 0\n",
    "$$\n",
    "\n",
    "$$\n",
    "    H_1: u_{4} - u_{6} > 0\n",
    "$$\n",
    "\n",
    "***\n",
    "$$\n",
    "    CI_{mean difference} = (\\bar{x_{6}} - \\bar{x_{4}}) \\pm Z_{\\frac{\\alpha}{2}}\\sqrt{\\frac{s_{6}^2}{n_{6}} + \\frac{s_{4}^2}{n_{4}}} \\\\\n",
    "    z_{0.005} = 2.576 \\\\\n",
    "$$\n",
    "***\n",
    "__6 Cylinder Constants:__\n",
    "\n",
    "$$\n",
    "    s_{6} = \\sqrt{\\frac{1}{n-1}\\sum_{x = 1}^{n}{(x_i - \\bar{x})^2}} \\approx 3.829 \\\\\n",
    "    n_{6} = 83 \\\\\n",
    "    \\bar{x}_{6} = \\frac{1}{n}\\sum_{i = 1}^{n}{x_i} = 19.973 \\\\\n",
    "$$\n",
    "***\n",
    "__4 Cylinder Constants:__\n",
    "$$\n",
    "    s_{4} = \\sqrt{\\frac{1}{n-1}\\sum_{x = 1}^{n}{(x_i - \\bar{x})^2}} \\approx 5.671 \\\\\n",
    "    n_{4} = 199 \\\\\n",
    "    \\bar{x}_{4} = \\frac{1}{n}\\sum_{i = 1}^{n}{x_i} = 29.284 \\\\\n",
    "$$\n",
    "***\n",
    "__Final CI Calculations__:\n",
    "$$\n",
    "    CI_{\\text{upper}} = (\\bar{x_{8}} - \\bar{x_{46}}) + Z_{\\frac{\\alpha}{2}}\\sqrt{\\frac{s_{8}^2}{n_{8}} + \\frac{s_{46}^2}{n_{46}}} \\approx  -10.808\\\\\n",
    "    CI_{\\text{lower}} = (\\bar{x_{8}} - \\bar{x_{46}}) - Z_{\\frac{\\alpha}{2}}\\sqrt{\\frac{s_{8}^2}{n_{8}} + \\frac{s_{46}^2}{n_{46}}} \\approx  -7.812\\\\\n",
    "    CI: [-10.808, -7.812]\n",
    "$$\n",
    "***\n",
    "__Conclusions:__\n",
    "\n",
    "Because the confidence interval is strictly lower than 0 (does not contain 0), we can conclude that there is significant evidence at the 95% confidence level that the mean of mpg  of 6 cylinder cars is lower than that of 4 cylinder cars.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z: 2.5758293035489004\n",
      "\n",
      "6 CYL\n",
      "mean: 19.973493975903615 n: 83 s: 3.828808779195717\n",
      "\n",
      "4 CYL\n",
      "mean: 29.283919597989957 n: 199 s: 5.670546150951293\n",
      "\n",
      "CI [-10.808414208391468 ,-7.812437035781215]\n"
     ]
    }
   ],
   "source": [
    "z = stats.norm.ppf(0.995)\n",
    "print(f\"z: {z}\\n\")\n",
    "\n",
    "# 6 cyl\n",
    "cyl6 = dfMPG.loc[dfMPG['cylinders'] == 6]\n",
    "mean6 = cyl6['mpg'].mean()\n",
    "n6 = len(cyl6)\n",
    "s6 = cyl6['mpg'].std()\n",
    "\n",
    "# 4 cyl\n",
    "cyl4 = dfMPG.loc[dfMPG['cylinders'] == 4]\n",
    "mean4 = cyl4['mpg'].mean()\n",
    "n4 = len(cyl4)\n",
    "s4 = cyl4['mpg'].std()\n",
    "\n",
    "# CI calculations\n",
    "lower = (mean6 - mean4) - z*np.sqrt(s6**2/n6 + s4**2/n4)\n",
    "upper = (mean6 - mean4) + z*np.sqrt(s6**2/n6 + s4**2/n4) \n",
    "\n",
    "print(f\"6 CYL\\nmean: {mean6} n: {n6} s: {s6}\\n\")\n",
    "print(f\"4 CYL\\nmean: {mean4} n: {n4} s: {s4}\\n\")\n",
    "print(f\"CI [{lower} ,{upper}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "[Back to top](#top)\n",
    "<a id='p3'></a>\n",
    "\n",
    "### [20 points] Problem 3 - Naps vs Coffee for Memory? \n",
    "\n",
    "It is estimated that [about 75% of adults](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4997286/) in the United States drink coffee. Often, coffee is used to replace the need for sleep. It works alright, or so we think. Let's find out, in this exciting homework problem!\n",
    "\n",
    "[One recent study](https://www.sciencedirect.com/science/article/pii/S1388245703002554) investigated the effects of drinking coffee, taking a nap, and having a [\"coffee-nap\"](https://lifehacker.com/naps-vs-coffee-which-is-better-when-youre-exhausted-1730643671) - the practice of drinking some coffee *and then* having a short nap. The study broke participants up into three groups of 10 participants each, where the groups would have a nap, or have a coffee, or have a coffee-nap, then perform a task where their reaction time was measured. In previous experiments the mean reaction time measurement was found to be normally distributed. The reaction time means (milliseconds, ms) and standard deviations for the three groups of participants are given in the table below.\n",
    "\n",
    "$$\n",
    "\\begin{array}{c|c|c|c}\n",
    "\\textrm{Group} & \\textrm{Sample Size} & \\textrm{Mean} & \\textrm{Standard Deviation} \\\\\n",
    "\\hline \n",
    "\\textrm{Coffee+Nap} & 10 & 451.3 & 31.9 \\\\ \n",
    "\\textrm{Coffee} & 10 & 494.2 & 39.6 \\\\ \n",
    "\\textrm{Nap} & 10 & 492.8 & 45.2 \\\\ \n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "**Part A**: Compute 95% t-confidence intervals for the mean reaction time measurement for participants in each of these three groups. (You should find three separate confidence intervals.) Do all computations in Python by hand, and report the results.\n",
    "\n",
    "1. Can you make any conclusions regarding whether coffee, naps or both (coffee-naps) are better for faster reaction times?\n",
    "2. Why did we use a t-distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "__Part A Work:__\n",
    "***\n",
    "$$\n",
    "    CI = \\bar{x} \\pm t_{\\alpha/2, n-1}\\left(\\frac{s}{\\sqrt{n}}\\right) \\\\\n",
    "    t_{0.025, 9} = 2.262 \\\\\n",
    "    n = 10\n",
    "$$\n",
    "***\n",
    "__Coffee t-CI:__\n",
    "\n",
    "$$\n",
    "    s = 39.6 \\\\\n",
    "    \\bar{x_{coffee}} = 494.2 \\\\\n",
    "    lower = 494.2 - 2.262*\\left(\\frac{39.6}{\\sqrt{10}}\\right) = 465.872 \\\\\n",
    "    upper = 494.2 - 2.262*\\left(\\frac{39.6}{\\sqrt{10}}\\right) = 522.528  \\\\\n",
    "    CI = [465.872,522.528]\n",
    "$$\n",
    "***\n",
    "__Nap t-CI:__\n",
    "\n",
    "$$\n",
    "    s = 45.2 \\\\\n",
    "    \\bar{x_{nap}} = 492.8 \\\\\n",
    "    lower = 492.8 - 2.262*\\left(\\frac{45.2}{\\sqrt{10}}\\right) = 461.866 \\\\\n",
    "    upper = 492.8 - 2.262*\\left(\\frac{45.2}{\\sqrt{10}}\\right) = 526.534 \\\\\n",
    "    CI = [461.866,526.534]\n",
    "$$\n",
    "***\n",
    "__Coffee + Nap t-CI:__\n",
    "\n",
    "$$\n",
    "    s = 31.9 \\\\\n",
    "    \\bar{x_{coffeenap}} = 451.3 \\\\\n",
    "    lower = 451.3 - 2.262*\\left(\\frac{31.9}{\\sqrt{10}}\\right) = 428.480 \\\\\n",
    "    upper = 451.3 - 2.262*\\left(\\frac{31.9}{\\sqrt{10}}\\right) = 474.120  \\\\\n",
    "    CI = [428.480,474.120]\n",
    "$$\n",
    "***\n",
    "__Conclusions:__\n",
    "\n",
    "1. All of the intervals overlap with each other in some way.  Because of this we can't conclude anything significantly just from these intervals, but we can see that the coffee/nap CI looks lower than the other two, and the coffee and the nap CI are about the same, with the nap CI just being a little bit wider\n",
    "2. We use the t-distribution because we know that the mean is distributed normally based on CLT, and the sample size is less than 30 for each of the groups.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 2.2621571627409915\n",
      "t-CI coffee: [465.8718665242781,522.5281334757218]\n",
      "t-CI nap: [461.86586785094374,526.5341321490563]\n",
      "t-CI coffee+nap: [428.48011470011295,474.1198852998871]\n"
     ]
    }
   ],
   "source": [
    "# constants for all CIs\n",
    "n = 10\n",
    "alpha = 0.05\n",
    "t = stats.t.ppf(1-alpha/2, n - 1)\n",
    "print(f\"t: {t}\")\n",
    "\n",
    "# coffee\n",
    "scoffee = 39.6\n",
    "meancoffee = 494.2\n",
    "lowercoffee = meancoffee - t * (scoffee / np.sqrt(n))\n",
    "uppercoffee = meancoffee + t * (scoffee / np.sqrt(n))\n",
    "\n",
    "# nap\n",
    "snap = 45.2\n",
    "meannap = 492.8\n",
    "lowernap = meancoffee - t * (snap / np.sqrt(n))\n",
    "uppernap = meancoffee + t * (snap / np.sqrt(n))\n",
    "\n",
    "# coffee+nap\n",
    "scoffeenap = 31.9\n",
    "meancoffeenap = 451.3\n",
    "lowercoffeenap = meancoffeenap - t * (scoffeenap / np.sqrt(n))\n",
    "uppercoffeenap = meancoffeenap + t * (scoffeenap / np.sqrt(n))\n",
    "\n",
    "# print to check everything out\n",
    "print(f\"t-CI coffee: [{lowercoffee},{uppercoffee}]\")\n",
    "print(f\"t-CI nap: [{lowernap},{uppernap}]\")\n",
    "print(f\"t-CI coffee+nap: [{lowercoffeenap},{uppercoffeenap}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B**: Use an appropriate hypothesis test to determine if there sufficient evidence, at the $\\alpha = 0.05$ significance level, to conclude that taking a nap promotes faster reaction time than drinking coffee.  Be sure to clearly explain the test that you're doing and state all hypotheses. Do all computations in Python, and report results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "__Part B Work:__\n",
    "$$\n",
    "    H_0:  \\mu_{nap}-\\mu_{coffee} = 0\\\\\n",
    "    H_1: \\mu_{nap} - \\mu_{coffee} > 0\\\\\n",
    "$$\n",
    "One tail t-test\n",
    "$$\n",
    "    t = \\frac{\\bar{x_{coffee}}-\\bar{x_{nap}}}{\\sqrt{\\frac{s_{coffee}^2}{n_{coffee}} + \\frac{s_{nap}^2}{n_{nap}}}} \\\\\n",
    "    t = 0.07367 \\\\\n",
    "    p = 1.83311 \\\\\n",
    "$$\n",
    "Reject if t > p (which it is not). \n",
    "***\n",
    "__Part B Conclusions:__\n",
    "We can conclude that there is not sufficient evidence to reject the null hypothesis.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07367196689546883 1.8331129326536335\n"
     ]
    }
   ],
   "source": [
    "t = (meancoffee - meannap) / (np.sqrt(snap**2/n + scoffee**2/n))\n",
    "p = stats.t.ppf(1-alpha, n-1)\n",
    "print(t, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part C**: Use an appropriate hypothesis test to determine if there is sufficient evidence, at the $\\alpha = 0.05$ significance level, to conclude that taking a coffee-nap promotes faster reaction time than only drinking coffee, or only having a nap.  Be sure to clearly explain the test that you're doing and state all hypotheses. Do all computations in Python, and report results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "__Part C Work:__\n",
    "Do the test twice, with coffee-nap and coffee, as well as coffee-nap and just-nap.\n",
    "$$\n",
    "    H_0:  \\mu_{coffeenap}-\\mu_{coffee} = 0\\\\\n",
    "    H_1: \\mu_{coffeenap} - \\mu_{coffee} > 0\\\\\n",
    "    AND \\\\\n",
    "    H_0:  \\mu_{coffeenap}-\\mu_{nap} = 0\\\\\n",
    "    H_1: \\mu_{coffeenap} - \\mu_{nap} > 0\\\\\n",
    "$$\n",
    "One tail t-test\n",
    "$$\n",
    "    t = \\frac{\\bar{x_{coffeenap}}-\\bar{x_{coffee}}}{\\sqrt{\\frac{s_{coffeenap}^2}{n_{coffeenap}} + \\frac{s_{coffee}^2}{n_{coffee}}}} \\\\\n",
    "    t = -2.66785 \\\\\n",
    "    p = 1.83311 \\\\\n",
    "$$\n",
    "$$\n",
    "    t = \\frac{\\bar{x_{coffeenap}}-\\bar{x_{nap}}}{\\sqrt{\\frac{s_{coffeenap}^2}{n_{coffeenap}} + \\frac{s_{nap}^2}{n_{nap}}}} \\\\\n",
    "    t = -2.3721 \\\\\n",
    "    p = 1.83311 \\\\\n",
    "$$\n",
    "***\n",
    "__Part C Conclusions:__\n",
    "We can conclude that there is not sufficient evidence to reject the null hypothesis. In fact, if we do the test the other way around we can conclude at the 0.05 significance level that coffee and a nap will give you worse reaction times than both just-coffee and just-nap.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coffee-nap vs coffee t: -2.6678557635847664 p: 1.8331129326536335\n",
      "Coffee-nap vs nap t: -2.37214516432695 p: 1.8331129326536335\n"
     ]
    }
   ],
   "source": [
    "t = (meancoffeenap - meancoffee) / (np.sqrt(scoffeenap**2/n + scoffee**2/n))\n",
    "p = stats.t.ppf(1-alpha, n-1)\n",
    "print(f\"Coffee-nap vs coffee t: {t} p: {p}\")\n",
    "t = (meancoffeenap - meannap) / (np.sqrt(scoffeenap**2/n + snap**2/n))\n",
    "p = stats.t.ppf(1-alpha, n-1)\n",
    "print(f\"Coffee-nap vs nap t: {t} p: {p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part D**: Compute a 95% confidence interval for the standard deviation of reaction time for coffee-nap takers. Do all computations in Python, and report the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "__Part D Conclusions:__\n",
    "$$\n",
    "    CI_{upper} = s * \\sqrt{\\frac{(n-1)}{\\chi^2_{(1-\\alpha, n-1)}}}\\\\\n",
    "    CI_{lower} = s * \\sqrt{\\frac{(n-1)}{\\chi^2_{(\\alpha, n-1)}}} \\\\\n",
    "    CI: [{5.369}, {14.249}]\n",
    "$$\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CI for std coffee-nap: [5.368558938203603,14.248901142126982]\n"
     ]
    }
   ],
   "source": [
    "lower = s * np.sqrt((n - 1)/stats.chi2.ppf(0.975, n - 1))\n",
    "upper = s * np.sqrt((n - 1)/stats.chi2.ppf(0.025, n - 1))\n",
    "print(f\"CI for std coffee-nap: [{lower},{upper}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "[Back to top](#top)\n",
    "<a id='p4'></a>\n",
    "\n",
    "### [20 points] Problem 4 - Bad Science for Fun and Profit \n",
    "\n",
    "[Data Dredging](https://en.wikipedia.org/wiki/Data_dredging) and [p-hacking](https://www.explainxkcd.com/wiki/index.php/882:_Significant) are umbrella terms for the dangerous practice of automatically testing a large number of hypotheses on the entirety or subsets of a single dataset in order to find statistically significant results. In this exercise we will focus on the idea of testing hypotheses on subsets of a single data set.  \n",
    "\n",
    "Nefaria Octopain has landed her first data science internship at an aquarium.  Her primary summer project has been to design and test a new feeding regimen for the aquarium's octopus population. To test her regimen, her supervisors have allowed her to deploy her new feeding regimen to 4 targeted octopus subpopulations of 40 octopuses each, every day, for a month. \n",
    "\n",
    "The effectiveness of the new diet is measured simply by the rate at which the food is consumed, which is simply defined to be the _proportion_ of octopuses that eat the food (POOTEF). The aquarium's standard octopus diet has a POOTEF of $0.90$.  Nefaria is hoping to land a permanent position at the aquarium when she graduates, so she's **really** motivated to show her supervisors that the POOTEF of her new diet regimen is a (statistically) significant improvement over their previous diet. \n",
    "\n",
    "The data from Nefaria's summer experiment can be found in `pootef.csv`. Load this dataset as a Pandas DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code to load\n",
    "# Should appear here\n",
    "# Name your dataframe\n",
    "# Whatever is clever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part A**: State the null and alternate hypotheses that Nefaria should test to see if her new feeding regimen is an improvement over the aquarium's standard feeding regimen with a POOTEF of $0.90$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B**: Test the hypothesis from **Part A** at the $\\alpha = 0.01$ significance level using a p-value test. Is there sufficient evidence for Nefaria to conclude that her feeding regimen is an improvement?   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part C**: Bummer, Nefaria thinks. This is the part where she decides to resort to some questionable science.  Maybe there is a reasonable _subset_ of the data for which her alternative hypothesis is supported?  Can she find it?  Can she come up for a reasonable justification for why this subset of the data should be considered while the rest should be discarded? \n",
    "\n",
    "Here are the **rules**: Nefaria cannot modify the original data (e.g. by adding nonexistent feedings or bites to certain groups or days) because her boss will surely notice.  Instead she needs to find a subset of the data for which her hypothesis is supported by a p-value test at the $\\alpha = 0.01$ significance level _and_ be able to explain to her supervisors why her sub-selection of the data is reasonable.  \n",
    "\n",
    "In addition to your explanation of why your successful subset of the data is potentially reasonable, be sure to thoroughly explain the details of the tests that you perform and show all of your Python computation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "[Back to top](#top)\n",
    "<a id='p5'></a>\n",
    "\n",
    "### [20 points] Problem 5 - Simple Linear Regression for the Consumption of Ice Cream Treats\n",
    "\n",
    "[Usain O'Flaherty](https://www.youtube.com/watch?v=LVeLz0FIj9A), the famous octopus athlete of the distinguished O'Flaherty family, has been keeping careful track of how much ice cream he eats after his training runs. He has stored the data in `icecream.csv`, where his ice cream consumption is measured in number of scoops, and his run distances are saved in units of miles. In this exercise you will construct a simple linear regression model for the response variable \"amount of ice cream consumed\" (`scoops`), using \"number of miles run\" (`miles`) as the feature. Load the data into a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfTreats = pd.read_csv(\"data/icecream.csv\")\n",
    "dfTreats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part A**: Perform a simple linear regression with `miles` as the feature and `scoops` as the response.  Report the estimated regression model in the form $Y = \\alpha + \\beta x$. Do all computations in Python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B**: Make a scatter-plot of the data with `miles` as the feature and `scoops` as the response, and overlay the estimated regression line.  Clearly label all relevant plot elements and include a legend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part C**: Give a physical interpretation of the coefficients $\\hat{\\alpha}$ and $\\hat{\\beta}$, estimated from your model. Is the relationship between run lengths and ice cream consumption positive or negative? Fully justify your responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part D**: How much ice cream does your simple linear regression model predict the runner will consume if they run a marathon (26.2 miles)? What are potential drawbacks to this model for ice cream consumption?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part E:** Compute a 66% confidence interval for the slope parameter, $\\beta$, ***by hand***. This means performing all calculations yourself in Python, as opposed to calling a simple Python function that gives you the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Part F**: Are there any other features you think should be added to the model, making this a *multiple* linear regression model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.6.5"
=======
   "version": "3.7.0"
>>>>>>> 8f0c89f636d911eb998005362d7a09099670d0a5
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
